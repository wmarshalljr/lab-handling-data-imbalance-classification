{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7.5: Handling data imbalance and classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import export_text\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95412, 336)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the cleaned dataset from Monday's lab:\n",
    "\n",
    "donors = pd.read_csv('learningSet_clean.csv')\n",
    "donors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95412, 336)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ODATEDW       int64\n",
       "TCODE         int64\n",
       "DOB           int64\n",
       "AGE         float64\n",
       "INCOME      float64\n",
       "             ...   \n",
       "RFA_2R       object\n",
       "RFA_2A       object\n",
       "GEOCODE2     object\n",
       "DOMAIN_A     object\n",
       "DOMAIN_B      int64\n",
       "Length: 336, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(donors.shape)\n",
    "donors.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SOLIH       89212\n",
       "VETERANS    84986\n",
       "NEXTDATE     9973\n",
       "EIC16           0\n",
       "EC1             0\n",
       "            ...  \n",
       "ETHC6           0\n",
       "ETHC5           0\n",
       "ETHC4           0\n",
       "ETHC3           0\n",
       "DOMAIN_B        0\n",
       "Length: 336, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulls = donors.isnull().sum()\n",
    "nulls.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping these columns\n",
    "# Far too many nulls to make any sense in our 336 variable data set\n",
    "# Manufacturing data may actually be worse than using the data\n",
    "\n",
    "donors = donors.drop(['SOLIH', 'VETERANS', 'NEXTDATE'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X, y split and dealing with categoricals / numericals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = donors.drop('TARGET_B', axis=1)\n",
    "y = donors['TARGET_B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num = X_train.select_dtypes(include = np.number)\n",
    "transformer = MinMaxScaler().fit(X_train_num) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized = transformer.transform(X_train_num)\n",
    "X_train_norm = pd.DataFrame(X_train_normalized, columns=X_train_num.columns)\n",
    "X_train_norm = X_train_norm.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_num = X_test.select_dtypes(include = np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_normalized = transformer.transform(X_test_num)\n",
    "X_test_norm = pd.DataFrame(X_test_normalized, columns=X_test_num.columns)\n",
    "X_test_norm = X_test_norm.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_categorical = X_train.select_dtypes(include = object)\n",
    "X_test_categorical = X_test.select_dtypes(include = object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(drop='first').fit(X_train_categorical)\n",
    "encoded = encoder.transform(X_train_categorical).toarray()\n",
    "\n",
    "cols = encoder.get_feature_names_out(input_features=X_train_categorical.columns)\n",
    "\n",
    "X_train_cat = onehot_encoded = pd.DataFrame(encoded, columns=cols)\n",
    "# X_train_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(drop='first').fit(X_test_categorical)\n",
    "encoded = encoder.transform(X_test_categorical).toarray()\n",
    "\n",
    "cols = encoder.get_feature_names_out(input_features=X_test_categorical.columns)\n",
    "\n",
    "X_test_cat = onehot_encoded = pd.DataFrame(encoded, columns=cols)\n",
    "# X_test_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = pd.concat([X_train_norm, X_train_cat], axis=1)\n",
    "# X_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = pd.concat([X_test_norm, X_test_cat], axis=1)\n",
    "# X_test_transformed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reset_index(drop=True) \n",
    "y_test = y_test.reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_automation(models, X_tr, y_tr, X_te, y_te):\n",
    "    for model in models:\n",
    "        model.fit(X_tr, y_tr)\n",
    "        print(f\"{model.__class__.__name__}: Train -> {model.score(X_tr, y_tr)}, Test -> {model.score(X_te, y_te)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: Train -> 0.9873180573569679, Test -> 0.9878949850652413\n"
     ]
    }
   ],
   "source": [
    "models = [LogisticRegression(random_state=69, solver='saga',\n",
    "                  multi_class='multinomial')]\n",
    "models_automation(models, X_train_transformed, y_train, X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(random_state=69, solver='saga',\n",
    "                  multi_class='multinomial').fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9878949850652413"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = LR.predict(X_test_transformed)\n",
    "LR.score(X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18157,     0],\n",
       "       [  231,   695]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  1.0\n",
      "recall:  0.7505399568034558\n",
      "f1:  0.8574953732264035\n"
     ]
    }
   ],
   "source": [
    "# Scores for unbalanced target:\n",
    "\n",
    "print(\"precision: \",precision_score(y_test,pred))\n",
    "print(\"recall: \",recall_score(y_test,pred))\n",
    "print(\"f1: \",f1_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing imbalanced data in 'TARGET_B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imbalance = pd.concat([X_train_norm, y_train],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_0 = train_imbalance[train_imbalance['TARGET_B'] == 0]\n",
    "category_1 = train_imbalance[train_imbalance['TARGET_B'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    72412\n",
       "1     3917\n",
       "Name: TARGET_B, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_imbalance['TARGET_B'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vtdsp7osBQ4"
   },
   "source": [
    "### Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "executionInfo": {
     "elapsed": 881,
     "status": "ok",
     "timestamp": 1620153938574,
     "user": {
      "displayName": "David Henriques",
      "photoUrl": "",
      "userId": "14332050621134291491"
     },
     "user_tz": -60
    },
    "id": "h11Cml2OsBQ4"
   },
   "outputs": [],
   "source": [
    "category_0_undersampled = resample(category_0, \n",
    "                                   replace=False, \n",
    "                                   n_samples = len(category_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "executionInfo": {
     "elapsed": 911,
     "status": "ok",
     "timestamp": 1620153941523,
     "user": {
      "displayName": "David Henriques",
      "photoUrl": "",
      "userId": "14332050621134291491"
     },
     "user_tz": -60
    },
    "id": "ye3GDr-osBQ4"
   },
   "outputs": [],
   "source": [
    "train_undersampled = pd.concat([category_0_undersampled, category_1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1073,
     "status": "ok",
     "timestamp": 1620153942665,
     "user": {
      "displayName": "David Henriques",
      "photoUrl": "",
      "userId": "14332050621134291491"
     },
     "user_tz": -60
    },
    "id": "1E6hDb9KsBQ5",
    "outputId": "808f720d-1f71-4886-dbac-cbe307d52212"
   },
   "outputs": [],
   "source": [
    "y_train_under = train_undersampled['TARGET_B'].copy()\n",
    "X_train_under = train_undersampled.drop('TARGET_B', axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3917\n",
       "1    3917\n",
       "Name: TARGET_B, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_under.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.8330188679245283\n",
      "recall:  0.9535637149028078\n",
      "f1:  0.8892245720040282\n"
     ]
    }
   ],
   "source": [
    "LR_under = LogisticRegression(random_state=69, solver='saga', multi_class='multinomial')\n",
    "LR_under.fit(X_train_under, y_train_under)\n",
    "pred_under = LR_under.predict(X_test_norm)\n",
    "\n",
    "print(\"precision: \",precision_score(y_test,pred_under))\n",
    "print(\"recall: \",recall_score(y_test,pred_under))\n",
    "print(\"f1: \",f1_score(y_test,pred_under))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yl_S3buhsBQ5"
   },
   "source": [
    "### Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "executionInfo": {
     "elapsed": 1097,
     "status": "ok",
     "timestamp": 1620153950004,
     "user": {
      "displayName": "David Henriques",
      "photoUrl": "",
      "userId": "14332050621134291491"
     },
     "user_tz": -60
    },
    "id": "O_-PHrFHsBQ5"
   },
   "outputs": [],
   "source": [
    "category_1_oversampled = resample(category_1, \n",
    "                                  replace=True, \n",
    "                                  n_samples = len(category_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "executionInfo": {
     "elapsed": 1441,
     "status": "ok",
     "timestamp": 1620153954965,
     "user": {
      "displayName": "David Henriques",
      "photoUrl": "",
      "userId": "14332050621134291491"
     },
     "user_tz": -60
    },
    "id": "cId9ETJmsBQ5"
   },
   "outputs": [],
   "source": [
    "train_oversampled = pd.concat([category_0, category_1_oversampled], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 849,
     "status": "ok",
     "timestamp": 1620153956428,
     "user": {
      "displayName": "David Henriques",
      "photoUrl": "",
      "userId": "14332050621134291491"
     },
     "user_tz": -60
    },
    "id": "wWqS7mhosBQ6",
    "outputId": "e7c04803-9deb-4903-afb8-f94530f24a4f"
   },
   "outputs": [],
   "source": [
    "y_train_over = train_oversampled['TARGET_B'].copy()\n",
    "X_train_over = train_oversampled.drop('TARGET_B', axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    72412\n",
       "1    72412\n",
       "Name: TARGET_B, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_over.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.9977973568281938\n",
      "recall:  0.978401727861771\n",
      "f1:  0.9880043620501635\n"
     ]
    }
   ],
   "source": [
    "LR_over = LogisticRegression(random_state=69, solver='saga', multi_class='multinomial')\n",
    "LR_over.fit(X_train_over, y_train_over)\n",
    "pred_over = LR_over.predict(X_test_norm)\n",
    "\n",
    "print(\"precision: \",precision_score(y_test,pred_over))\n",
    "print(\"recall: \",recall_score(y_test,pred_over))\n",
    "print(\"f1: \",f1_score(y_test,pred_over))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=100, k_neighbors=3)\n",
    "X_train_SMOTE,y_train_SMOTE = sm.fit_resample(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  1.0\n",
      "recall:  0.7505399568034558\n",
      "f1:  0.8574953732264035\n"
     ]
    }
   ],
   "source": [
    "LR.fit(X_train_SMOTE, y_train_SMOTE)\n",
    "\n",
    "print(\"precision: \",precision_score(y_test,pred))\n",
    "print(\"recall: \",recall_score(y_test,pred))\n",
    "print(\"f1: \",f1_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion:\n",
    "\n",
    "# If I did the test / train split and scaling / encoding correctly...\n",
    "# ...then we see that the scores after balancing the target are far superior\n",
    "# In this case, I would use the oversampled data, which had a higher set of scores than all the others \n",
    "# This makes sense given the size of the imbalance in TARGET_B"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
